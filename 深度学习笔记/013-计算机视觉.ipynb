{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d58c4d",
   "metadata": {},
   "source": [
    "# 图像增广"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05397dd8-708c-4b0c-a3ad-8e8a3d007bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be7ed06-4b55-4335-9ab3-a9e808eb12de",
   "metadata": {},
   "source": [
    "## 网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4039872c-695e-42f0-af0a-c73d5bbf1b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.set_figsize()\n",
    "img = d2l.Image.open('../img/cat1.jpg')\n",
    "d2l.plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b7ca630-f621-411b-a379-a6820de85bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0318, 0.0000, 0.1356, 0.0000, 0.0000, 0.0375, 0.0000, 0.0000,\n",
       "        0.0205], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply(img, aug, num_rows=2, num_cols=4, scale=1.5):\n",
    "    Y = [aug(img) for _ in range(num_rows * num_cols)]\n",
    "    d2l.show_images(Y, num_rows, num_cols, scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbca83c6-c405-45c3-980c-fbaedca8749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply(img, torchvision.transforms.RandomHorizontalFlip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5dd4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply(img, torchvision.transforms.RandomVerticalFlip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aa5930",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_aug = torchvision.transforms.RandomResizedCrop(\n",
    "    (200, 200), scale=(0.1, 1), ratio=(0.5, 2))\n",
    "apply(img, shape_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f62407",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply(img, torchvision.transforms.ColorJitter(\n",
    "    brightness=0.5, contrast=0, saturation=0, hue=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f7d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply(img, torchvision.transforms.ColorJitter(\n",
    "    brightness=0, contrast=0, saturation=0, hue=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab206efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_aug = torchvision.transforms.ColorJitter(\n",
    "    brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5)\n",
    "apply(img, color_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb71569",
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomHorizontalFlip(), color_aug, shape_aug])\n",
    "apply(img, augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06185fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = torchvision.datasets.CIFAR10(train=True, root=\"../data\",\n",
    "                                          download=True)\n",
    "d2l.show_images([all_images[i][0] for i in range(32)], 4, 8, scale=0.8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8753ce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augs = torchvision.transforms.Compose([\n",
    "     torchvision.transforms.RandomHorizontalFlip(),\n",
    "     torchvision.transforms.ToTensor()])\n",
    "\n",
    "test_augs = torchvision.transforms.Compose([\n",
    "     torchvision.transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48284a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10(is_train, augs, batch_size):\n",
    "    dataset = torchvision.datasets.CIFAR10(root=\"../data\", train=is_train,\n",
    "                                           transform=augs, download=True)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                    shuffle=is_train, num_workers=d2l.get_dataloader_workers())\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b098f77",
   "metadata": {},
   "source": [
    "# 微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a03036",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
